{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wyssalkl/BuisnessWebsite/blob/master/Untitled2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "lc6OdjZ9Wlxi",
        "outputId": "00c4b460-ddb2-41d9-de0e-a2f7ee60d03a"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/wikitree_anon.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-59c66338e5dd>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Lire les lignes du fichier texte dans un DataFrame pandas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/wikitree_anon.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\",\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m7000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Créer un nouveau graphe vide\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    910\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 912\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 577\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    578\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1659\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1660\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1661\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1662\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1663\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    857\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    860\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/wikitree_anon.csv'"
          ]
        }
      ],
      "source": [
        "from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas\n",
        "import pandas as pd\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "\n",
        "# Lire les lignes du fichier texte dans un DataFrame pandas\n",
        "df = pd.read_csv(\"/content/wikitree_anon.csv\", sep=\",\", nrows=7000)\n",
        "\n",
        "# Créer un nouveau graphe vide\n",
        "G = nx.Graph()\n",
        "\n",
        "for _, row in df.iterrows():\n",
        "    values = row.values.tolist()\n",
        "    if len(values) < 3:\n",
        "        continue\n",
        "    source = str(values[0])\n",
        "    target = str(values[1])\n",
        "    weight = int(values[2])\n",
        "    G.add_edge(source, target, weight=weight)\n",
        "\n",
        "# Fonction pour afficher le graphe\n",
        "def afficher_graphe():\n",
        "    # Définir la disposition des nœuds du graphe\n",
        "    pos = nx.spring_layout(G, k=0.15, iterations=20)\n",
        "\n",
        "    # Dessiner le graphe avec la nouvelle disposition\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    nx.draw(G, pos, with_labels=True, node_size=100, font_size=10, node_color='skyblue', edge_color='gray', width=0.5)\n",
        "    plt.title(\"Graphe facebook\")\n",
        "    plt.show()\n",
        "\n",
        "# Fonction pour afficher le diagramme de degré\n",
        "def afficher_diagramme():\n",
        "    # Créer un histogramme des degrés\n",
        "    degrees = [degree for node, degree in G.degree()]\n",
        "    plt.hist(degrees, bins=100, color='skyblue', edgecolor='gray')\n",
        "    plt.xlabel('Degré')\n",
        "    plt.ylabel('Fréquence')\n",
        "    plt.title('Distribution des degrés')\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "# Fonction pour afficher les composants connectés\n",
        "def afficher_composants_connectes():\n",
        "    # Calculer les composants connectés\n",
        "    composants = list(nx.connected_components(G))\n",
        "    print(f\"Il y a {len(composants)} composants connectés dans le graphe.\")\n",
        "\n",
        "# Fonction pour afficher les chemins les plus courts\n",
        "def afficher_chemins():\n",
        "    # Calculer les chemins les plus courts entre chaque paire de nœuds\n",
        "    chemins = dict(nx.all_pairs_shortest_path(G))\n",
        "    for source, paths in chemins.items():\n",
        "        for target, path in paths.items():\n",
        "            print(f\"Chemin le plus court de {source} à {target}: {path}\")\n",
        "\n",
        "# Fonction pour afficher le coefficient de clustering\n",
        "def afficher_coefficient_clustering():\n",
        "    # Calculer le coefficient de clustering\n",
        "    coefficient = nx.average_clustering(G)\n",
        "    print(f\"Le coefficient de clustering moyen est {coefficient}.\")\n",
        "\n",
        "# Fonction pour afficher l'analyse de la densité\n",
        "def afficher_densite():\n",
        "    # Calculer la densité\n",
        "    densite = nx.density(G)\n",
        "    print(f\"La densité du graphe est {densite}.\")\n",
        "\n",
        "# Fonction pour afficher l'analyse de la centralité\n",
        "def afficher_centralite():\n",
        "    # Calculer la centralité\n",
        "    centralite = nx.degree_centrality(G)\n",
        "    print(f\"La centralité des nœuds a été calculée et égale à {centralite}\")\n",
        "\n",
        "# Appel des fonctions\n",
        "afficher_graphe()\n",
        "afficher_diagramme()\n",
        "afficher_composants_connectes()\n",
        "afficher_chemins()\n",
        "afficher_coefficient_clustering()\n",
        "afficher_densite()\n",
        "afficher_centralite()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Lire les premières 6000 lignes du fichier texte dans un DataFrame pandas\n",
        "df = pd.read_csv(\"/content/wikitree_anon.csv\", sep=\",\", nrows=6000)\n",
        "\n",
        "# Créer un nouveau graphe vide\n",
        "G = nx.Graph()\n",
        "\n",
        "for _, row in df.iterrows():\n",
        "    values = row.values.tolist()\n",
        "    if len(values) < 3:\n",
        "        continue\n",
        "    source = str(values[0])\n",
        "    target = str(values[1])\n",
        "    weight = int(values[2])\n",
        "    G.add_edge(source, target, weight=weight)\n",
        "\n",
        "# Appliquer l'algorithme k-clique\n",
        "#k_clique_communities = list(nx.algorithms.community.k_clique_communities(G, 3))  # Par exemple, chercher les cliques de taille 3\n",
        "\n",
        "# Appliquer l'algorithme Louvain\n",
        "# louvain_communities = list(nx.community.greedy_modularity_communities(G))\n",
        "\n",
        "# Appliquer l'algorithme démon/angel\n",
        "demon_angel_communities = list(nx.community.label_propagation_communities(G))\n",
        "\n",
        "# Afficher les résultats\n",
        "#print(\"Résultats de l'algorithme k-clique:\")\n",
        "#print(k_clique_communities)\n",
        "#print(\"\\nRésultats de l'algorithme Louvain:\")\n",
        "#print(louvain_communities)\n",
        "print(\"\\nRésultats de l'algorithme démon/angel:\")\n",
        "print(demon_angel_communities)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "-VjJpAu5ERof",
        "outputId": "0793387a-0e02-43a2-a8cc-6c87bcf84bde"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'pd' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-311016e8cfbf>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Lire les premières 6000 lignes du fichier texte dans un DataFrame pandas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/wikitree_anon.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\",\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m6000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Créer un nouveau graphe vide\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mG\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Lire les données à partir du fichier CSV\n",
        "df = pd.read_csv(\"/content/wikitree_anon.csv\", sep=\",\", nrows=7000)\n",
        "\n",
        "\n",
        "\n",
        "# Diviser les données en ensembles d'apprentissage et de test (80% / 20%)\n",
        "edges = list(G.edges(data=True))\n",
        "edge_features = [(edge[0], edge[1], edge[2]['weight']) for edge in edges]\n",
        "edge_labels = [1 if G.has_edge(edge[0], edge[1]) else 0 for edge in edges]  # 1 for existing edges, 0 for missing edges\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(edge_features, edge_labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Extraire les caractéristiques des liens\n",
        "X_train_features = [(edge[2],) for edge in X_train]\n",
        "X_test_features = [(edge[2],) for edge in X_test]\n",
        "\n",
        "# Entraîner un classifieur RandomForest pour prédire les liens manquants\n",
        "clf = RandomForestClassifier()\n",
        "clf.fit(X_train_features, y_train)\n",
        "\n",
        "# Faire des prédictions sur l'ensemble de test\n",
        "predictions = clf.predict(X_test_features)\n",
        "\n",
        "# Évaluer les performances du modèle\n",
        "accuracy = accuracy_score(y_test, predictions)\n",
        "print(\"Accuracy:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gzdyCfgiEkrX",
        "outputId": "9742d85a-19e1-4b94-9dd2-961d5df6fb24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eIfhUJX90DNT"
      },
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}